 # Copyright (c) 2022, salesforce.com, inc.
 # All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

datasets:
  longterm_caption:
    # data_dir: ${env.data_dir}/datasets
    data_type: images # [images|videos|features]

    build_info:
      # Be careful not to append minus sign (-) before split to avoid itemizing
      annotations:
        train:
          # url:
          #     - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/aokvqa/aokvqa_v1p0_train.json
          storage:
              - /local1/whu/data/hm3d/train_data/Captions/llava-3d_data_Feb26_v6_medium_13K_caption_episodic_mem_v2_natural_cap_sum_diff.json
        val:
          # url:
          #     - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/aokvqa/aokvqa_v1p0_val.json
          #     - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/aokvqa/specialized_vocab_train.json
          storage:
              - /local1/whu/data/hm3d/train_data/Captions/llava-3d_data_Feb26_v6_medium_13K_caption_episodic_mem_v2_natural_cap_sum_diff.json
              # - aokvqa/annotations/specialized_vocab_train_lavis.json
              # - aokvqa/annotations/large_vocab_train_lavis.json
        test:
          # url:
          #     - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/aokvqa/aokvqa_v1p0_test.json
          #     - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/aokvqa/specialized_vocab_train.json
          storage:
              - /local1/whu/data/hm3d/train_data/Captions/llava-3d_data_Feb26_v6_medium_13K_caption_episodic_mem_v2_natural_cap_sum_diff.json
              # - aokvqa/annotations/specialized_vocab_train_lavis.json
      images:
          storage: /local1/leisongao/data/3dllm/rgb_features
